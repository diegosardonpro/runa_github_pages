import os
import re
import json
import requests
import psycopg2
import uuid
from bs4 import BeautifulSoup
from urllib.parse import urlparse, urljoin
from supabase import create_client, Client
from src.utils.logger import get_logger

# --- CONFIGURACIÓN ---
# v1.2: Forzar trigger final
URLS_TABLE = 'urls_para_procesar'
ASSETS_TABLE = 'activos_curados'
SURVEYS_TABLE = 'encuestas_anonimas'
IMAGES_OUTPUT_DIR = 'output_images'

# --- INFRAESTRUCTURA COMO CÓDIGO (IaC) ---
SCHEMA_SQL = f"""
CREATE TABLE IF NOT EXISTS public.{URLS_TABLE} (
    id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    created_at timestamptz DEFAULT now() NOT NULL,
    url text NOT NULL UNIQUE,
    estado text DEFAULT 'pendiente' NOT NULL, -- pendiente, en_proceso, completado, error
    intentos smallint DEFAULT 0 NOT NULL,
    ultimo_error text
);

CREATE TABLE IF NOT EXISTS public.{ASSETS_TABLE} (
    id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    created_at timestamptz DEFAULT now() NOT NULL,
    url_original text NOT NULL,
    titulo text,
    resumen text,
    contenido_html text,
    tags text,
    ruta_imagen_local text,
    url_imagen_original text
);

CREATE TABLE IF NOT EXISTS public.{SURVEYS_TABLE} (
    id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    created_at timestamptz DEFAULT now() NOT NULL,
    asset_id bigint REFERENCES public.{ASSETS_TABLE}(id) ON DELETE SET NULL,
    tipo_dispositivo text,
    rango_edad text,
    nivel_confianza_digital integer,
    limites_acceso text
);

ALTER TABLE public.{URLS_TABLE} DISABLE ROW LEVEL SECURITY;
ALTER TABLE public.{ASSETS_TABLE} DISABLE ROW LEVEL SECURITY;
ALTER TABLE public.{SURVEYS_TABLE} DISABLE ROW LEVEL SECURITY;
"""

# --- FUNCIONES ---
def setup_database_schema(logger):
    logger.info("Iniciando configuración de schema de base de datos...")
    conn = None
    try:
        db_url = os.getenv('SUPABASE_URL')
        db_password = os.getenv('SUPABASE_DB_PASSWORD')
        if not db_url or not db_password: raise ValueError("Secretos de BD no encontrados.")
        
        project_ref = urlparse(db_url).hostname.split('.')[0]
        db_host = f"db.{project_ref}.supabase.co"
        conn_string = f"postgresql://postgres:{db_password}@{db_host}:5432/postgres"
        
        conn = psycopg2.connect(conn_string)
        cursor = conn.cursor()
        logger.debug("Ejecutando SQL para crear tablas si no existen.")
        cursor.execute(SCHEMA_SQL)
        conn.commit()
        logger.info("Schema de la base de datos verificado/creado con éxito.")
    except Exception as e:
        logger.error(f"Error al configurar el schema de la BD: {e}", exc_info=True)
        raise
    finally:
        if conn: conn.close()

def get_supabase_client(logger):
    url = os.getenv('SUPABASE_URL')
    key = os.getenv('SUPABASE_SERVICE_KEY')
    if not url or not key: raise ValueError("Secretos de Supabase no encontrados.")
    logger.debug("Cliente de Supabase creado.")
    return create_client(url, key)

# ... (Otras funciones como scrape_article_data, enrich_with_ai, download_image irían aquí)

# --- LÓGICA PRINCIPAL ---
def main():
    run_id = str(uuid.uuid4())[:8]
    logger = get_logger(f"curator-{run_id}")

    logger.info("--- ======================================= ---")
    logger.info(f"--- INICIANDO EJECUCIÓN DEL CURADOR (RUN ID: {run_id}) ---")
    logger.info("--- ======================================= ---")
    try:
        # 1. Asegurar que la infraestructura de la BD esté lista
        setup_database_schema(logger)
        supabase = get_supabase_client(logger)

        # 2. Obtener lote de URLs para procesar
        logger.info(f"Buscando URLs con estado 'pendiente' en la tabla '{URLS_TABLE}'...")
        response = supabase.table(URLS_TABLE).select('id, url').eq('estado', 'pendiente').limit(5).execute()
        urls_to_process = response.data

        if not urls_to_process:
            logger.info("No hay nuevas URLs para procesar. Finalizando ejecución.")
        else:
            logger.info(f"Se encontraron {len(urls_to_process)} URLs para procesar.")
            logger.debug(f"URLs a procesar: {[item['url'] for item in urls_to_process]}")
            
            ids_in_process = [item['id'] for item in urls_to_process]
            supabase.table(URLS_TABLE).update({'estado': 'en_proceso'}).in_('id', ids_in_process).execute()
            logger.debug(f"Marcando IDs {ids_in_process} como 'en_proceso'.")

            # 3. Procesar cada URL (Simulación)
            for item in urls_to_process:
                # ... (lógica de procesamiento simulada)
                pass

    except Exception as e:
        logger.error(f"Ha ocurrido un error fatal en el script: {e}", exc_info=True)
        exit(1)
    finally:
        logger.info(f"--- FINALIZANDO EJECUCIÓN DEL CURADOR (RUN ID: {run_id}) ---")

if __name__ == "__main__":
    main()